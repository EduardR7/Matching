<!-- ![image alt="drawing" height="200"](https://github.com/EduardR7/Matching/assets/126398449/8ef414ad-3402-48b2-bb75-2ade5b45d46e) -->
<img src="https://github.com/EduardR7/Matching/assets/126398449/8ef414ad-3402-48b2-bb75-2ade5b45d46e" alt="drawing" height="300">

# Мэтчинг товаров в маркетплейсе
## Заказчик
Интернет-магазин

## Описание задачи
Необходимо подготовить расчетную модель систему поиска похожих элементов (мэтчинг).
На вход приходит вектор значений последнего скрытого слоя нейросети, 72 фичи.
На выходе нужно получить максиимально близкий элемент из базового набора.
Имеющиеся данные:
- Baseset База эмбедингов более 3 млн значений, т.е. 3 млн значений категории таргета.
- Trainset выборка эмбедингов в 100 тыс. строк: новые товары, которым проставлено совпадение из базы
- Testset выборка в 100 тыс. строк.
### Особенность задачи мэтчинга
Отличие задачи мэтчинга от стандартных задач бинарной/многоклассовой классификации и регрессии, в том,
что количество категорий теоретически равно количеству значений в Baseset, т.е. в нашей задаче - 3млн категорий, поэтому, задачу невозможно решить с помощью многоклассовых бустингов
#### Метрика
- В качестве метрики принята acc@5, если среди 5-и рекомендованных кандидатов имеется таргет, то значение метрики равно 1, иначе 0.

## Результаты работы и выводы
<!-- - Так как полный набор, особенно Baseset, существенно нагружает вычислительные мощности, был построен статистически близкий учебный miniset 600тыс/20тыс/20тыс строк, который гораздо быстрее считается -->
1. Выделено влияние каждого признака/измерения на скор, найден оптимальный скейлер.
2. С помощью FAISS получена метрика acc@5 - 75,55%
3. Для дополнительного ранжирования с помощью Catboost, использовалось около 15 метрик scipy.distance. Метрика улучшена на 2.65%, до 78,3% на тестовой выборке.

## Технологии
pandas, numpy, faiss, catboost,scipy
<!-- планируемые optuna, pipeline, fast api,   docker -->

## Статус проекта
Закончен

<!--
## Результаты работы и выводы
 - Так как полный набор, особенно Baseset, существенно нагружает вычислительные мощности, был построен статистически близкий учебный miniset 600тыс/20тыс/20тыс строк, который гораздо быстрее считается
- Построена бейзлайн модель, и построены гистограммы всех 72 измерений. На miniset измерено влияние каждого из 72 измерений на общий скор. Выделены "нехарактерные" измерения, и отдельно измерено влияние каждого на общий скор.
- Дополнительно исследовано влияние масштабирования (scalers) на метрику
- `FAISS` имеет встроенные методы работы с расстояниями, коллинераностью и другими скалярными признаками. Была выполнена подготовка к ранжированию для бустов.
- Для ранжирования применен метод обучения на сконкатенированных векторах с добавлением расстояний как дополнительных признаков.
- С помощью FAISS получена метрика acc@5 - 0.7555
- Выполнено ранжирование с помощью CatBoost, взято 100 кандидатов вместо 5, улучшение оказалось значительное - acc@5 = 0.8066
- Суммарно, скор увеличен на 6,76%, что является отличным улучшением
- Так как количество данных большое, около 80тыс со значением = 1, возможно можно еще добавить значящие фичи.
-->
