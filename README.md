<!-- ![image alt="drawing" height="200"](https://github.com/EduardR7/Matching/assets/126398449/8ef414ad-3402-48b2-bb75-2ade5b45d46e) -->
<img src="https://github.com/EduardR7/Matching/assets/126398449/8ef414ad-3402-48b2-bb75-2ade5b45d46e" alt="drawing" height="300">

# Мэтчинг товаров в маркетплейсе

## Технологии
pandas, numpy, faiss, catboost
<!-- планируемые optuna, pipeline, fast api,   docker -->


## Описание задачи
Заказчику необходимо внедрить систему поиска похожих элементов (мэтчинг).
Существует базовый набор, baseset, каждый элемент baseset это фактически отдельная категория.
На вход приходит вектор значений последнего скрытого слоя нейросети, эмбединг содержит 72 измерения.
На выходе нужно получить максиимальной близкий элемент из базового набора.

Имеющиеся данные:
- Baseset База эмбедингов более 3 млн значений
- Trainset выборка эмбедингов в 100 тыс. строк: новые товары, которым проставлено совпадение из базы
- Testset выборка в 100 тыс. строк

## Особенность задачи мэтчинга
Отличие задачи мэтчинга от стандартных задач бинарной/многоклассовой классификации и регрессии, в том,
что количество категорий теоретически равно количеству значений в Baseset, т.е. в нашей задаче - 3млн категорий, поэтому, задачу невозможно решить с помощью многоклассовых бустингов

#### Метрика
- В качестве метрики принята acc@5, если среди 5-и рекомендованных кандидатов имеется таргет, то значение метрики равно 1, иначе 0.

## Результаты работы и выводы
- Так как полный набор, особенно Baseset, существенно нагружает вычислительные мощности, был построен статистически близкий учебный miniset 600тыс/20тыс/20тыс строк, который гораздо быстрее считается
- Построена бейзлайн модель, и построены гистограммы всех 72 измерений. На miniset измерено влияние каждого из 72 измерений на общий скор. Выделены "нехарактерные" измерения, и отдельно измерено влияние каждого на общий скор.
- Дополнительно исследовано влияние масштабирования (scalers) на метрику
- `FAISS` имеет встроенные методы работы с расстояниями, коллинераностью и другими скалярными признаками. Была выполнена подготовка к ранжированию для бустов.
- Для ранжирования применен метод обучения на сконкатенированных векторах с добавлением расстояний как дополнительных признаков.

    <!-- - обучение на расстояниях до рандомных векторов - слишком простая тренировочная выборка. близкие векторы разделять трудно
    - обучение на расстоях до близких векторов - слишком сложная обучающая выборка
    - обучение на сконкатенированных векторах - результаты хорошие, но недостаточные
    -->
    
<!--
Вывод:
- Не недооценивать важность `EDA`

- Время работы алгоритма для инференса выборки из 100_000 кандидатов на i5-9600K
    - для 50 соседей: 32 минуты (10 минут поиск `FAISS` и 22 минуты на инференс(включая генерацию фич)
    - для 100 соседей: 52 минуты (10 минут поиск `FAISS` и 42 минуты на инференс(включая генерацию фич)

#### Что нужно доделать:
- Поискать иные подходы (возможно, считать разницу между признаками)
- Поэкспериментировать с другими скейлерами, например `QuantileTransformer`
- Попробовать заменить `FAISS` на `Quadrant` или `Annoy`
- Сделать код ранжирования эффективнее (Отрабатывает долго. Вероятно, из-за множества инициализаций)
- Тюнить модель
- Купить больше оперативной памяти =)
-->
